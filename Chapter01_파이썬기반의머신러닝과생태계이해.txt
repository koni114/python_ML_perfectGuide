## Chapter01_파이썬 기반의 머신러닝과 생태계 이해 ##

01. 머신러닝의 개념.
데이터마이닝, 영상 인식, 음성 인식, 자연어 처리에서 개발자가 데이터나
업무 로직의 특성을 직접 감안한 프로그램을 만들 경우
난이도와 개발 복잡도가 너무 높아질 수 밖에 없는 분야에서 머신러닝이 급속하게
발전하고 있음.

* 데이터 전쟁
garbage in, garbage out. 
즉, 데이터의 질이 좋지 않으면, 결과도 좋을 수 없음.
머신러닝은 데이터에 매우 의존적.

* R vs Python
R : 통계학자들이 검증한 방대한 통계 분석 패키지 존재.
Python : 소리없이 프로그래밍 세계를 점령하고 있는 언어.
- 쉽고 뛰어난 개발 생산성
- 오픈 소스 계열의 전폭적인 지지를 받고 있음
- 인터프리터 언어의 특성상 속도는 느림. 대신에 뛰어난 확장성. 유연성. 호환성.
- 머신러닝 애플리케이션과 결합한 다양한 영역에서 이용
- 엔터프라이즈 아키텍처로의 확장 및 마이크로서비스 기반의 실시간 연계.
  기업환경으로의 확산이 가능.
- ** 딥러닝 프레임워크인 텐서플로, 케라스, 파이토치 등에서 파이썬 우선 정책으로
   파이썬을 지원하고 있음

02. 파이썬 머신러닝 생태계를 구성하는 주요 패키지.
- 머신러닝 패키지: Scikit-Learn
- 행렬/선형대수/통계 패키지 : numpy
- 데이터 핸들링 : Matplotlib
- 시각화 : Matplotlib, Seaborn

**  Anaconda
Anaconda를 설치하면 기본적으로, 넘파이, 판다스, 맷플롯립, 시본, 주피터노트북까지
함께 설치됨
Anaconda prompt : Anaconda를 이용해 패키지를 설치할 때 사용
		 관리자 권한으로 실행해야함.

03. 넘파이
Numerical Python을 의미하는 넘파이로써
선형대수 기반의 프로그램을 쉽게 만들 수 있도록 지원하는 대표적인 패키지.
루프를 사용하지 않고 대량 데이터의 배열 연산을 가능케 함.
-> 빠른 배열 연산 속도를 보장
C/C++과 같은 저수준 언어 기반의 호환 API를 제공
많은 파이썬 기반의 패키지가 넘파이를 이용해 데이터 처리를 수행하지만,
편의성과 다양한 API 지원 측면에서 아쉬운 부분이 많음.
판다스의 편리성에는 미치지 못하는 것이 현실.

넘파이를 이해하는 것은 파이썬 기반의 머신러닝에서 매우 중요!

* 넘파이 개요
import numpy as np

넘파이 기반 데이터 타입 : ndarray.
해당 함수를 이용해 넘파이에서 다차원 배열을 쉽게 생성하고 다양한 연산 수행 가능
array()는 파이썬의 리스트 같은 다양한 인자를 입력 받아,
ndarray()로 변환하는 기능을 수행.

ndarray의 shape 변수는 ndarray의 크기, 행과 열의 수를 튜플 형태로 가지고 있음

array1 = np.array([1, 2, 3])
print('array 1 type :', type(array1))
print('array1 형태:', array1.shape)

array2 = np.array([[1,2,3], [4,5,6]])
print('array 2 type :', type(array2))
print('array2 형태:', array2.shape)

array3 = np.array([[1, 2, 3]])
print('array3 type :', type(array3))
print('array3 array 형태:', array3.shape) --> (1, 3) : 명확한 차원을 확인하기 위함! 

array의 차원을 ndarray.ndim 을 이용해 확인 가능.
print('array1 : {:0}차원, array2 : {:1}차원, array3 : {:2}차원'.format(array1.ndim, array2.ndim, array3.ndim))

ndarray 내의 데이터 값은 숫자 값, 문자열 값, 불 값 모두 가능.
숫자형의 경우, int형(8, 16, 32bit)
	       unsigned int형(8 ,16, 32bit)
	       float형(16bit, 32bit, 64bit, 128bit)

ndarray에 다른 형의 데이터는 불가능.
ndarray.dtype 속성으로 확인 가능.
데이터의 형이 다른 list를 ndarray로 변경하였을 경우, 더 큰 데이터 타입으로 형 변환을 일괄 적용.

ndarray 내 데이터 값의 타입 변경도 astype() 메서드를 이용해 할 수 있음.
해당 함수를 이용하면, 많은 메모리를 사용하는 경우를 막을 수 있음
메모리를 더 절약해야 할 때 보통 이용

파이썬 기반 머신러닝 알고리즘은 대부분 메모리로 데이터를 전체 로딩한 후,
이를 기반으로 알고리즘을 적용하기 때문에 대용량의 데이터를 로딩할 때는 수행속도가 느려지거나
메모리 부족으로 오류가 발생할 수 있음.

array_int = np.array([1,2,3])
array_float = array_int.astype('float64')
print(array_float, array_float.dtype)

array_int1 = array_float.astype('int32')
print(array_int1, array_int1.dtype)

array_float1 = np.array([1.1, 2.1, 3.1])
array_int2   = array_float1.astype('int32')
print(array_int2, array_int2.dtype)

** ndarray를 편라하게 생성하기 - arrange, zeros, ones
특정 크기와 차원을 가진 ndarray를 연속값이나 0, 1로 초기화해 쉽게 생성해야 할 필요가 있는
경우가 발생할 수 있음.
이 경우, arrange(), zeros(), ones()를 이용해 쉽게 ndarray를 생성 할 수 있음.

# arange -> range 함수와 거의 유사.
sequnce_array = np.arange(10)
print(sequence_array) -> 0 ~ 9까지 값.
print(sequence_array.dtype, sequence_array.shape)

# zeros -> 모든 값을 0으로 채운 해당 shape를 가진 ndarray를 반환.
# ones  -> 모든 값을 1로 채운 해당 shape를 가진 ndarray로 반환.
dtype을 정해주지 않으면, float64 형의 데이터로 ndarray로 채움.
zero_array = np.zeros((3, 2), dtype = 'int32')
print(zero_array)
print(zero_array.dtype, zero_array.shape)

one_array = np.ones((3, 2))
print(one_array)
print(one_array.dtype, one_array.shape)

# ndarray의 차원과 크기를 변경하는 reshape()
array1 = np.arange(10)
print('array1:\n' ,array1)

array2 = np.reshape(2, 5)
print('array2:\n')

array3 = np.reshape(5, 2)
print('array3:\n' ,array3)

reshape()의 인자로 -1를 적용하는 경우, 자동으로 크기에 맞게 reshape 해줌.
array1.reshape(-1, 5)
array1.reshape(5, -1)

-1 인자는 주로 reshape(-1, 1)과 같은 형태로 자주 사용.
-> 컬럼이 한개고 n개의 row를 가지는 2차원 형태로 변경하고 싶을 때,

** 넘파이의 ndarray의 데이터 세트 선택 - 인덱싱(indexing)
- 특정한 데이터만 추출 : 원하는 위치의 인덱스 값을 지정
- 슬라이싱(slicing) : 연속된 인덱스 상의 ndarray를 추출하는 방식.
- 팬시 인덱싱(fancy indexing) : 일정한 인덱싱 집합을 리스트 또는 ndarray 형태로 지정해 해당 데이터의 ndarray를 반환
- 불린 인덱싱(boolean indexing) : 특정 조건에 해당하는 여부인 True/False 값 인덱싱 집합을 기반으로
                                             True에 있는 인덱스 위치에 있는 데이터 ndarray 반환

# 특정 데이터 추출
array1[3] 하면, 더이상 ndarray 형식이 아니라, 내부 형으로 바뀜 ex) float64
-1, -2는 뒤에서 부터 인덱싱 하겠다는 의미.
2차원에서 axis 0 : row, axis 1 : column을 지칭.

# 슬라이싱
:를 이용하여 슬라이싱 가능.
규칙은 기존 python에서의 슬라이싱과 동일.
2차원 뒤에 오는 인덱스를 없애면 1차원 ndarray를 반환.

# 팬시 인덱싱
ex) array2d[[0, 1], 0:2]

# 불린 인덱싱
조건 필터링과 검색을 동시에 할 수 있기 때문에 매우 자주 사용되는 인덱싱 방식.

array1d = np.arange(1, 10)
array3   = array1d[array1d > 5]
print("array3 : ", array3 )

# 행렬의 정렬 sort(), argsort()
넘파이에서 행렬을 대표하는 방법 np.sort(), nparray.sort()
정렬된 행렬의 인덱스를 반환 argsort()

np.sort() : 원 행렬은 그대로 유지, 정렬된 행렬을 반환
ndarray.sort() : 원 행렬 자체를 정렬한 형태로 반환. return 값은 None

org_array =  np.array([3, 1, 9, 5])
print('원본 행렬 :', org_array)
sort_array1 = np.sort(org_array)
내림차순 정렬시 [::-1] 이용.

행렬이 2차원 이상인 경우에 axis 축 값 설정을 통해 로우 방향, 또는 컬럼 방향으로 정렬을
수행할 수 있음.

array2d = np.array([8, 12], [7, 1])
sort_array2d_axis0 = np.sort(array2d, axis = 0)
print("sort_array2d_axis0 :", sort_array2d_axis0)

sort_array2d_axis1 = np.sort(array2d, axis = 1)
print("sort_array2d_axis1  :", sort_array2d_axis1)

정렬된 행렬의 인덱스 반환
np.argsort() : 정렬 행렬의 원본 행렬 인덱스를 ndarray 형으로 반환

argsort()는 넘파이에서 활용도가 높음.
넘파이의 ndarray는 RDBMS의 TABLE 컬럼이나 
판다스의 dataframe 칼럼과 같은 메타 데이터를 가질 수 없음.
즉, 실제 값과 그 메타 데이터를 각각 ndarray로 가져야 함. 

** 선형 대수 연산 - 행렬 내적과 전치 행렬 구하기
# 행렬 내적(dot)
A와 B의 내적은 np.dot()을 이용해 계산이 가능.

A = np.array([[1,2,3],[4,5,6]])
B = np.array([[7, 8], [9, 10], [11, 12]])
dot_product = np.dot(A, B)

# 전치 행렬(transpose)
행과 열 위치를 교환한 원소로 구성한 행렬.
np.transpose()를 이용

04. 데이터 핸들링 - 판다스
판다스는 파이썬에 데이터 처리를 위해 존재하는 가장 인기있는 라이브러리
일반적으로 대부분의 데이터 세트는 2차원 데이터
판다스는 행과 열로 이뤄진 2차원 데이터를 효율적으로 가공/처리할 수 있는 다양하고 훌륭한 기능 제공

넘파이의 2차원 데이터를 다루는 수준은 어렵. 
저수준 API가 대부분.
파이썬의 리스트, 컬렉션, 넘파이 등의 내부 데이터 뿐만 아니라 CSV 등의 파일을 쉽게 DataFrame으로
변경해 데이터의 가공/분석을 편리하게 수행할 수 있게 만들어줌.

판다스의 핵심 객체는 DataFrame
다른 객체인 Index, Series를 이해하는 것도 중요.

Series 와 DataFrame의 가장 큰 차이는,
Series는 컬럼이 1개, DataFrame은 여러개.

import pandas as pd
판다스는 다양한 포멧으로 된 파일을 DataFrame으로 로딩할 수 있는 편리한 API를 제공.

pd.read_csv() 는 호출 시 파일명 인자로 들어온 파일을 로딩해 DataFrame 객체로 반환
데이터 파일의 첫 번째 줄에 있던 칼럼 문자열이 DataFrame의 칼럼으로 할당.
모든 DataFrame 내에 데이터는 생성되는 순간 고유의 Index를 가지게 됨.

df1.shape 를 이용해 객체 수를 확인!
컬럼의 타입, Null 데이터 개수, 데이터 분포도 등의 메타 데이터 등도 조회가 가능
df1.info()
object type은 문자열로 생각해도 무방.
non-null 옆에 숫자는 말 그대로 non-null의 개수를 보여줌. 나머지 개수는 null 이라고 생각하면 됨.

df1.describe()
칼럼별 숫자형 데이터값의 n-percentile 분포도, 평균값, 최댓값, 최솟값을 나타냄.
오직 숫자형 칼럼의 분포도만 조사. 자동으로 object 타입의 컬럼은 출력에서 제외

* Series
Series는 Index와 단 하나의 칼럼으로 구성된 데이터 세트
한 개의 컬럼의 데이터만 출력되지 않고 맨 왼쪽에 0부터 시작하는 순차 값이 있음.
value_counts() 는 series 객체에서만 정의되어 있는 함수

Pclass의 value_counts를 확인해보면, 인덱스가 단순히 0부터 시작하는 순차 값이 아님.
즉 인덱스는 단순히 순차 값과 같은 의미 없는 식별자만 할당하는 것이 아니라 고유성이 보장된다면 의미 있는 데이터값 할당도 가능
인덱스는 DataFrame, Series가 만들어진 후에도 변경할 수 있음.
인덱스는 또한 숫자형 뿐만 아니라 문자열도 가능. 단, 고유성이 보장되어야 함.

** DataFrame과 리스트, 딕셔너리, 넘파이 ndarray 상호 변환
사이킷런의 많은 API는 DataFrame을 인자로 입력 받을 수 있지만, 기본적으로 넘파이 ndarray를 입력 인자로 사용하는 경우가 대부분.
따라서 DataFrame과 ndarray 간의 변환은 많이 일어남.

** Numpy, list, dict -> DataFrame
DataFrame으로 변환 시 칼럼명을 지정해 주어야 함.(안하면 자동으로 생성)
판다스 DataFrame 객체의 생성 인자 data는 리스트나 딕셔너리 또는 넘파이 ndarray를 입력 받고
생성 인자 columns는 컬럼명 리스트를 입력받아 쉽게 DataFrame을 생성할 수 있음.

* list, ndarray -> dataFrame

col_name1 = ['col1']
list1     = [1, 2, 3]
array1    = np.array(list1)
print("array1 shape :", array1.shape)
df_list1 = pd.dataFrame(list1, columns = col_name1)

2차원 list 또한 dataFrame으로 변경 가능.
col_names2 = ['col1', ]

col_names2 = ['col1', 'col2', 'col3']
list2 = [[1,2,3], [4,5,6]]
pd.DataFrame(list2, columns = col_names2)

* dict -> dataFrame

일반적으로 딕셔너리를 DataFrame으로 변환 시에는 딕셔너리의 키(Key)는 칼럼명으로, 딕셔너리의 Value는 키에 해당하는 칼럼 데이터로 변환
따라서 키의 경우는 문자열, 값의 경우 리스트 형태로 딕셔너리를 구성.

dict = {'col1':[1, 11], 'col2': [2, 22], 'col3' : [3, 33]}
df_dict = pd.DataFrame(dict)
print(df_dict)

* dataFrame -> numpy
많은 머신러닝 패키지가 기본 데이터 형으로 넘파이 ndarray를 사용.
따라서 dataFrame으로 데이터 조작 후, 최종 ndarray로 변환하는 경우가 대부분
values()를 이용해서 변환 가능

array3 = df_dict.values
print('df_dict.values 타입:', type(array3), 'df_dict.values shape :', array3.shape)

* dataFrame -> list 
list3 = df_dict.values.tolist()

* dataFrame -> dict
dict3 = df_dict.to_dict('list')

** DataFrame의 칼럼 데이터 세트 생성과 수정.
titanic_df['Age_0'] = 0                                # 새로운 Age_0 컬럼의 값을 0으로 할당하고 싶은 경우,
titanic_df['Age_by_10'] = titanic_df['Age'] * 10 # 기존에 있는 컬럼 값을 변환하여 새로운 컬럼에 추가하고 싶은 경우,
titanic_df['Age'] = titanic_df['Age'] * 10          # 기존에 있는 컬럼 값을 변환하여 다시 기존 컬럼에 덮어 쓰고 싶은 경우,

** DataFrame 데이터 삭제
Drop() 메서드를 이용. 혼동 주의!
DataFrame.drop(labels = None, axis = 0, index = None, columns = None, level = None, inplace = False, errors = 'raise')
1. axis
  0인 경우, row drop  1인 경우,  column drop
  label에 원하는 칼럼 명을 입력하고, axis = 1로 두면, 지정된 칼럼을 drop 함
  label에 인덱스를 입력(무조건 인덱스로 간주)하고, axis = 0으로 두면 지정된 로우를 drop 함

titanic_drop_df = titanic_df.drop('Age_0', axis = 1)

2. inplace 
T : 자신의 DataFrame 내의 컬럼의 데이터를 삭제. return은 None
F : 자신의 DataFrame 내의 컬럼은 삭제 되지 않고, return 결과 컬럼만 삭제 됨

titanic_df.drop(['Age_0', 'Age_by_10'], axis = 1, inplace = True)

pd.set_option('display.width', 1000)
pd.set_option('display.max_colwidth', 15)
print('## before axis 0 drop ###')
print(titanic_df.head(3))
titanic_df.drop([0, 1, 2], axis = 0, inplace = True)

print("### after axis 0 drop ###")
print(titanic_df.head(3))

## Index 객체
RDBMS의 PK와 유사하게 DataFrame, Series의 레코드를 고유하게 식별하는 개체
DataFrame.index, Series.index 명령어를 통해 index 추출 가능
반환된 index 객체의 실제 값은 1차원 ndarray로 확인 가능
한번 만들어진 index 객체에 값을 변경할 수 없음.

indexes = titanic_df.index
print(indexes)

* reset_index()
DataFrame 및 Series에 reset_index() 를 수행하면 새롭게 인덱스를 연속 숫자 형으로 할당.
기존 인덱스는 index라는 새로운 칼럼 명으로 추가
인덱스가 연속형 숫자가 아닐 때, 새로운 연속형 숫자 인덱스를 생성할 때 자주 사용.

print(value_counts)
print('value counts 객체 변수 타입 :', type(value_counts))
new_reset_counts = value_counts.reset_index(inplace = False)
print("## after reset index ##")
print(new_reset_counts)
print('new reset counts 객체 변수 타입', type(new_reset_counts))

Series에 reset_index를 적용하면 Series -> DataFrame 으로 변경됨
Drop = True 로 설정하면, 기존 인덱스는 새로운 칼럼으로 추가되지 않고 삭제(drop) 됨.

## 데이터 셀렉션 및 필터링
판다스의 데이터 셀렉션 및 필터링은 넘파이와 유사한 부분도 있고, 다른 부분도 있으므로 유의. 
numpy : '[]' 연산자 내 단일 값 추출, 슬라이싱, 펜시 인덱싱, 불린 인덱싱을 통해 데이터를 추출.
pandas : ix[], iloc[], loc[] 연산자를 통해 동일한 작업 수행

DataFrame 뒤에 있는 '[]' 연산자는 칼럼만 지정할 수 있는 '칼럼 지정 연산자'로 이해하는 게 혼돈을 막는 가장 빠른 방법
즉, titanic_df[0] 같은 표현식은 오류를 발생 -> 칼럼을 지정하는 값이 아니기 때문
titanic_df[0, 0] 등도 마찬가지로 오류 발생
만약 수치 값이 index를 지칭하는 값이라면, 오류 X
ex) titanic_df[0:3] ( but 비추천. numpy, Series와 다르기 때문)

불린 인덱싱 기능도 제공(자주 사용)
titanic_df[titanic_df['Pclass'] == 3].head(3)

# ix[ ] 
ix[ ] 는 ix[0 , 'Pclass'] 와 같이 지정 가능
ix[0, 2:3] 도 가능
-> but 사라질 예정!!!!! 사용시 deprecation warning 출력

# 명칭 기반 인덱싱과 위치 기반 인덱싱
명칭(Label) 기반 인덱싱     : 칼럼의 명칭을 기반으로 위치를 지정하는 방식
위치(Position) 기반 인덱싱 : 0으로 출발하는 가로축, 세로축 좌표 기반의 행과 열 위치를 기반으로 데이터 지정.

만약 index 가 숫자로 이루어진 값이라고 해보자. 그렇다면, 인덱스를 통해 슬라이싱 할 때,
위치를 뜻하는 것인지 실제 인덱스 값을 뜻하는 것인지 알 수가 없음.
실제로는 '명칭 기반 인덱싱이 우선이다' 라고 생각하면 혼선은 사라질 수 있지만... 뭐 어쨋든 그렇다.
따라서 loc[ ], iloc[ ] 를 사용하게 됨

# DataFrame iloc[ ] 
iloc[ ] : 위치 기반 인덱싱만 허용
명칭 기반 인덱싱이 들어올 경우, error 발생

data_df.iloc[0, 0]
data_df.iloc['one', 0] # error 발생

# DataFrame loc[]
명칭 기반으로 데이터를 추출
명칭 기반이라고해서 반드시 문자열은 아님
data_df.loc['one', 'Name']
data_df.loc[1, 'Name']

주의!! ':' 를 이용하여 슬라이싱을 할 때, 일반적으로는 끝 값 -1 를 해서 슬라이싱을 하지만,  loc[] 에서는 끝 값을 포함!
why? 위치 기반이기 때문에 숫자형이 아닌 경우 -1을 할 수 없기 때문
iloc는 -1을 한 값을 슬라이싱 함 --> 헷갈리지 말자!

# 불린 인덱싱
ix, iloc, loc 보다 더 자주 사용하는 인덱싱 방법
why? 슬라이싱은 특정 조건에 의해 발생되는 경우가 많은데, 이를 한 번에 처리할 수 있기 때문
불린 인덱싱은 ix[ ], loc[ ], iloc[ ] 공통으로 지원
but iloc[ ]는 정수형 값이 아닌 불린 값에 대해서는 지원하지 않기 때문에 불린 인덱싱이 지원 되지 않음

두 개의 문구는 같은 값을 return
titanic_df[titanic_df['Age']> 60][['Name', 'Age']].head(10)
titanic_df.loc[titanic_df['Age'] > 60, ['Name', 'Age']].head(10)

## 정렬, Aggregation 함수, GroupBy 적용
DataFrame과 Series의 정렬을 위해서는 sort_values() 메서드를 이용

1. by : 해당 컬럼으로 정렬 수행
2. ascending : True 이면 오름차순, False 이면 내림차순
3. inplace 

titanic_sorted = titanic_df.sort_values(by = ['Name'])
titanic_sorted.head(3)

여러 개의 컬럼으로 정렬 시, list 형태로 입력하면 됨

# Aggregation 함수 적용
DataFrame에서 min(), max(), sum(), count().
DataFrame에서 바로 해당 함수를 호출 하면, 모든 컬럼에 대해서 적용된 결과를 return 함.

titanic_df.count()
titanic_df[['Age', 'Fare']].mean()

# groupby 적용
DataFrame의 groupby() 사용 시 입력 파라미터 by에 칼럼을 입력하면 대상 컬럼으로 groupby 됨
결과 값은 DataFrameGroupBy 라는 또 다른 형태의 DataFrame을 반환

titanic_groupby = titanic_df.groupby(by = 'Pclass')
print(type(titanic_groupby))

DataFrame의 groupby 결과에 aggregation 함수를 적용하면,
groupby() 대상 컬럼을 제외한 모든 칼럼에 해당 aggregation 함수를 적용
titanic_groupby = titanic_df.groupby('Pclass').count()
titanic_groupby 

groupby()는 agg() 를 이용해 이 같은 처리가 가능
agg_format = {'Age' : 'max', 'SibSp' : 'sum', 'Fare': 'mean'}
titanic_df.groupby('Pclass').agg(agg_format)

## 결손 데이터 처리하기
컬럼에 값이 없는 NULL인 경우를 의미
넘파이는 NaN으로 표시
NaN 값이 있는 경우, 총합 등의 함수 연산 시 제외가 됨

NaN 여부를 확인하는 API    : isna()
NaN 값을 다른 값으로 대체 : fillna()

titanic_df.isna().sum()

# fillna 로 결손 데이터 대체하기
fillna( )를 이용해 반환 값을 다시 받거나 inplace = True 파라미터를 fillna( )에 추가해야 
실제 데이터 세트 값이 변경된다는 점 조심!

titanic_df['Cabin'] = titanic_df['Cabin'].fillna('C000')

## apply lambda 식으로 데이터 가공
판다스는 apply 함수에 lambda 식을 결합해 DataFrame이나 Series의 레코드별로 데이터를 가공하는 기능 제공

lambda_square = lambda x : x ** 2
print('3의 제곱은 ,', lambda_square(3))

lambda 식을 이용할 때 여러 개의 값을 입력 인자로 사용해야 할 경우, map( ) 함수를 결합
a = [1, 2, 3]
squares = map(lambda x : x ** 2, a)
list(squares)

판다스의 DataFrame의 lambda 식은 파이썬의 이러한 lambda 식을 그대로 적용한 것
'Name' 칼럼의 문자열 개수를 별도의 칼럼은 'Name_len'에 생성

titanic_df['Name_len'] = titanic_df['Name'].apply(lambda x : len(x))

나이가 15세 미만이면 child, 그렇지 않으면 Adult로 구분하는 새로운 칼럼 'Child_Adult' 만들기
titanic_df['Child_Adult'] = titanic_df['Age'].apply(lambda x : 'Child' if x <= 15, else 'Adult')

* 주의해야 할 점. if else 구문을 사용 할 때, if 절의 경우 반환 값을 먼저 기술해야 함.
lambda 식 ':' 기호의 오른편에 반환 값이 있어야 하기 때문!

if, else 만 지원하고, else if는 지원하지 않음.
else if 를 사용하고 싶으면, else 절 내부에 if를 다시 사용해서 적용해야 함 
